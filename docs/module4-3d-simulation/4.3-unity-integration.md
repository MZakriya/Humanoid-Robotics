---
title: Unity Integration
sidebar_label: Unity Integration
description: Integrating humanoid robots with Unity simulation environment for advanced 3D visualization and development
---

# 4.3 Unity Integration

## Overview

Unity integration provides high-fidelity visualization and simulation capabilities for humanoid robotics development. Unlike Gazebo, Unity excels in visual quality and user interaction, making it ideal for human-in-the-loop testing, teleoperation interfaces, and advanced visualization. This chapter covers the complete integration process from Unity setup to ROS communication.

## Unity Environment Setup

### Installation and Prerequisites

1. **Unity Hub Installation:**
   - Download Unity Hub from the Unity website
   - Install Unity Hub and create an account
   - Install Unity 2021.3 LTS or later (recommended for stability)

2. **Required Packages:**
   - Unity Robotics Package (com.unity.robotics.ros-tcp-connector)
   - Unity Robotics Simulation Package (com.unity.robotics.urdf-importer)
   - Universal Render Pipeline (URP) for advanced rendering

3. **System Requirements:**
   - Windows 10/11, macOS 10.14+, or Linux Ubuntu 18.04+
   - Dedicated GPU with DirectX 11 or OpenGL 4.5 support
   - 8GB+ RAM for complex humanoid models

### Initial Project Configuration

```csharp
// ProjectSettings/RoboticsSettings.cs - Example configuration script
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;

public class RoboticsProjectSetup : MonoBehaviour
{
    [Header("ROS Connection Settings")]
    public string rosIpAddress = "127.0.0.1";
    public int rosPort = 10000;
    public bool autoConnectOnStart = true;

    [Header("Simulation Settings")]
    public float simulationTimeStep = 0.01f;
    public bool useFixedTimestep = true;

    void Start()
    {
        if (autoConnectOnStart)
        {
            ConnectToROS();
        }

        if (useFixedTimestep)
        {
            Time.fixedDeltaTime = simulationTimeStep;
        }
    }

    void ConnectToROS()
    {
        ROSConnection ros = ROSConnection.GetOrCreateInstance();
        ros.Initialize(rosIpAddress, rosPort);
        Debug.Log($"Connected to ROS at {rosIpAddress}:{rosPort}");
    }
}
```

## Robot Model Integration

### URDF Import Process

Unity provides the URDF Importer package for importing robot models from ROS:

```csharp
// URDF Robot Controller for Unity
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Sensor;
using RosMessageTypes.Control;

public class UnityRobotController : MonoBehaviour
{
    [Header("Robot Configuration")]
    public string robotName = "simple_humanoid";
    public Transform[] jointTransforms;  // Assigned in inspector
    public string[] jointNames;          // Corresponding ROS joint names

    [Header("ROS Topics")]
    public string jointStateTopic = "/joint_states";
    public string jointCommandTopic = "/joint_commands";

    private ROSConnection ros;
    private float[] currentJointPositions;
    private float[] targetJointPositions;

    void Start()
    {
        ros = ROSConnection.GetOrCreateInstance();

        // Subscribe to joint states
        ros.Subscribe<JointStateMsg>(jointStateTopic, OnJointStateReceived);

        // Initialize joint position arrays
        currentJointPositions = new float[jointTransforms.Length];
        targetJointPositions = new float[jointTransforms.Length];

        // Initialize target positions
        for (int i = 0; i < targetJointPositions.Length; i++)
        {
            targetJointPositions[i] = jointTransforms[i].localEulerAngles.z;
        }
    }

    void OnJointStateReceived(JointStateMsg jointState)
    {
        // Update joint positions based on ROS messages
        for (int i = 0; i < jointNames.Length; i++)
        {
            for (int j = 0; j < jointState.name.Count; j++)
            {
                if (jointState.name[j] == jointNames[i])
                {
                    targetJointPositions[i] = (float)jointState.position[j];
                    break;
                }
            }
        }
    }

    void Update()
    {
        // Smoothly interpolate joint positions
        for (int i = 0; i < jointTransforms.Length; i++)
        {
            currentJointPositions[i] = Mathf.Lerp(
                currentJointPositions[i],
                targetJointPositions[i],
                Time.deltaTime * 10f  // Interpolation speed
            );

            // Apply rotation to joint
            jointTransforms[i].localEulerAngles = new Vector3(0, 0, Mathf.Rad2Deg * currentJointPositions[i]);
        }
    }

    public void SendJointCommand(float[] positions)
    {
        var jointCmd = new JointStateMsg();
        jointCmd.name = jointNames;
        jointCmd.position = new double[positions.Length];

        for (int i = 0; i < positions.Length; i++)
        {
            jointCmd.position[i] = positions[i];
        }

        ros.Publish(jointCommandTopic, jointCmd);
    }
}
```

### Physics Configuration for Humanoid Models

```csharp
// UnityPhysicsController.cs - Physics setup for humanoid
using UnityEngine;

[RequireComponent(typeof(Rigidbody))]
public class UnityPhysicsController : MonoBehaviour
{
    [Header("Balance Parameters")]
    public float balanceStiffness = 0.1f;
    public float balanceDamping = 0.05f;
    public Transform centerOfMassTarget;

    [Header("Joint Configuration")]
    public ConfigurableJoint[] joints;
    public float[] jointStiffness = {1000f, 1000f, 1000f}; // Hip, Knee, Ankle

    private Rigidbody rb;
    private Vector3 targetCOM;

    void Start()
    {
        rb = GetComponent<Rigidbody>();
        if (centerOfMassTarget != null)
        {
            rb.centerOfMass = transform.InverseTransformPoint(centerOfMassTarget.position);
        }

        ConfigureJoints();
    }

    void ConfigureJoints()
    {
        for (int i = 0; i < joints.Length && i < jointStiffness.Length; i++)
        {
            var joint = joints[i];

            // Configure spring for joint stiffness
            var jointDrive = joint.angularXDrive;
            jointDrive.positionSpring = jointStiffness[i];
            jointDrive.positionDamper = jointStiffness[i] * balanceDamping;
            joint.angularXDrive = jointDrive;

            var yDrive = joint.angularYZDrive;
            yDrive.positionSpring = jointStiffness[i];
            yDrive.positionDamper = jointStiffness[i] * balanceDamping;
            joint.angularYZDrive = yDrive;
        }
    }

    void FixedUpdate()
    {
        ApplyBalanceForces();
    }

    void ApplyBalanceForces()
    {
        if (centerOfMassTarget != null)
        {
            // Calculate balance error
            Vector3 comError = centerOfMassTarget.position - rb.worldCenterOfMass;

            // Apply corrective forces
            Vector3 balanceForce = comError * balanceStiffness;
            rb.AddForceAtPosition(balanceForce, rb.worldCenterOfMass);
        }
    }
}
```

## ROS Communication Integration

### ROS-TCP Connector Setup

```csharp
// ROSManager.cs - Central ROS communication manager
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using Unity.Robotics.ROSTCPConnector.MessageGeneration;
using RosMessageTypes.Std;
using RosMessageTypes.Sensor;
using RosMessageTypes.Geometry;

public class ROSManager : MonoBehaviour
{
    [Header("ROS Topics")]
    public string[] subscribedTopics;
    public string[] publishedTopics;

    [Header("Robot Control")]
    public string robotCommandTopic = "/unity_robot_command";
    public string robotStateTopic = "/unity_robot_state";

    private ROSConnection ros;
    private bool isConnected = false;

    void Start()
    {
        InitializeROS();
    }

    void InitializeROS()
    {
        ros = ROSConnection.GetOrCreateInstance();

        // Register all required topics
        RegisterSubscribers();
        RegisterPublishers();

        // Connect to ROS
        ros.OnConnected += OnROSConnected;
        ros.OnDisconnected += OnROSDisconnected;

        ros.Connect();
    }

    void RegisterSubscribers()
    {
        // Register common robot topics
        ros.Subscribe<JointStateMsg>("/joint_states", OnJointStateReceived);
        ros.Subscribe<TwistMsg>("/cmd_vel", OnVelocityCommandReceived);
        ros.Subscribe<UInt8Msg>("/robot_control_mode", OnControlModeReceived);
    }

    void RegisterPublishers()
    {
        // Publishers will be registered automatically when first published
    }

    void OnJointStateReceived(JointStateMsg msg)
    {
        // Process joint state messages
        // This can be forwarded to robot controller components
    }

    void OnVelocityCommandReceived(TwistMsg msg)
    {
        // Process velocity commands
        // Forward to robot movement controller
    }

    void OnControlModeReceived(UInt8Msg msg)
    {
        // Handle control mode changes
        Debug.Log($"Control mode changed to: {msg.data}");
    }

    void OnROSConnected()
    {
        isConnected = true;
        Debug.Log("Connected to ROS");
    }

    void OnROSDisconnected()
    {
        isConnected = false;
        Debug.LogWarning("Disconnected from ROS");
    }

    public void PublishRobotState(Transform robotTransform, float[] jointPositions)
    {
        if (!isConnected) return;

        var stateMsg = new JointStateMsg();
        stateMsg.header = new std_msgs.Header();
        stateMsg.header.stamp = new builtin_interfaces.Time();
        stateMsg.header.frame_id = robotTransform.name;

        // Fill in joint names and positions
        stateMsg.name = new string[jointPositions.Length];
        stateMsg.position = new double[jointPositions.Length];

        for (int i = 0; i < jointPositions.Length; i++)
        {
            stateMsg.name[i] = $"joint_{i}";
            stateMsg.position[i] = jointPositions[i];
        }

        ros.Publish(robotStateTopic, stateMsg);
    }

    public void PublishIMUData(Vector3 linearAccel, Vector3 angularVel, Quaternion orientation)
    {
        if (!isConnected) return;

        var imuMsg = new ImuMsg();
        imuMsg.header = new std_msgs.Header();
        imuMsg.header.stamp = new builtin_interfaces.Time();
        imuMsg.header.frame_id = "imu_link";

        // Set linear acceleration
        imuMsg.linear_acceleration = new geometry_msgs.Vector3();
        imuMsg.linear_acceleration.x = linearAccel.x;
        imuMsg.linear_acceleration.y = linearAccel.y;
        imuMsg.linear_acceleration.z = linearAccel.z;

        // Set angular velocity
        imuMsg.angular_velocity = new geometry_msgs.Vector3();
        imuMsg.angular_velocity.x = angularVel.x;
        imuMsg.angular_velocity.y = angularVel.y;
        imuMsg.angular_velocity.z = angularVel.z;

        // Set orientation
        imuMsg.orientation = new geometry_msgs.Quaternion();
        imuMsg.orientation.w = orientation.w;
        imuMsg.orientation.x = orientation.x;
        imuMsg.orientation.y = orientation.y;
        imuMsg.orientation.z = orientation.z;

        ros.Publish("/imu/data", imuMsg);
    }
}
```

## Humanoid-Specific Simulation Features

### Inverse Kinematics in Unity

```csharp
// UnityHumanoidIK.cs - Inverse kinematics for humanoid
using UnityEngine;

public class UnityHumanoidIK : MonoBehaviour
{
    [Header("IK Targets")]
    public Transform leftFootTarget;
    public Transform rightFootTarget;
    public Transform leftHandTarget;
    public Transform rightHandTarget;

    [Header("IK Solvers")]
    public Transform leftHip;
    public Transform leftKnee;
    public Transform leftAnkle;
    public Transform rightHip;
    public Transform rightKnee;
    public Transform rightAnkle;

    [Header("IK Parameters")]
    public float ikWeight = 1.0f;
    public float maxDistance = 2.0f;

    void OnAnimatorIK(int layerIndex)
    {
        // Set IK positions and rotations
        SetLimbIK(AvatarIKGoal.LeftFoot, leftFootTarget, leftAnkle);
        SetLimbIK(AvatarIKGoal.RightFoot, rightFootTarget, rightAnkle);
        SetLimbIK(AvatarIKGoal.LeftHand, leftHandTarget, leftHandTarget);
        SetLimbIK(AvatarIKGoal.RightHand, rightHandTarget, rightHandTarget);
    }

    void SetLimbIK(AvatarIKGoal goal, Transform target, Transform effector)
    {
        Animator animator = GetComponent<Animator>();

        if (target != null)
        {
            animator.SetIKPositionWeight(goal, ikWeight);
            animator.SetIKRotationWeight(goal, ikWeight);
            animator.SetIKPosition(goal, target.position);
            animator.SetIKRotation(goal, target.rotation);
        }
        else
        {
            animator.SetIKPositionWeight(goal, 0);
            animator.SetIKRotationWeight(goal, 0);
        }
    }

    // Custom IK solver for leg (2-bone IK)
    public void SolveLegIK(Transform hip, Transform knee, Transform ankle, Vector3 targetPosition)
    {
        Vector3 hipToTarget = targetPosition - hip.position;
        float hipToTargetLength = hipToTarget.magnitude;

        // Calculate knee position using 2-bone IK
        Transform parent = hip.parent;
        Vector3 worldUp = parent != null ? parent.up : Vector3.up;

        // Get the length of both bones
        float upperBoneLength = Vector3.Distance(hip.position, knee.position);
        float lowerBoneLength = Vector3.Distance(knee.position, ankle.position);
        float totalLength = upperBoneLength + lowerBoneLength;

        if (hipToTargetLength > totalLength)
        {
            // If target is out of reach, stretch toward it
            Vector3 direction = hipToTarget.normalized;
            knee.position = hip.position + direction * upperBoneLength;
            ankle.position = hip.position + direction * totalLength;
        }
        else
        {
            // Calculate knee position using law of cosines
            float cosAngle = (upperBoneLength * upperBoneLength + totalLength * totalLength - hipToTargetLength * hipToTargetLength) /
                           (2 * upperBoneLength * totalLength);
            float angle = Mathf.Acos(Mathf.Clamp(cosAngle, -1f, 1f));

            Vector3 planeNormal = Vector3.Cross(hipToTarget, worldUp).normalized;
            Vector3 bisector = Quaternion.AngleAxis(angle * Mathf.Rad2Deg * 0.5f, planeNormal) * hipToTarget.normalized;
            Vector3 kneeDirection = Vector3.Cross(planeNormal, bisector).normalized;

            float distance = Mathf.Sqrt(Mathf.Max(0f, upperBoneLength * upperBoneLength -
                           Mathf.Pow(totalLength * 0.5f, 2))) * 2f;
            knee.position = hip.position + kneeDirection * distance;

            // Position ankle at target
            ankle.position = targetPosition;
        }
    }
}
```

### Sensor Simulation in Unity

```csharp
// UnityCameraSensor.cs - Camera sensor simulation
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Sensor;

public class UnityCameraSensor : MonoBehaviour
{
    [Header("Camera Configuration")]
    public Camera sensorCamera;
    public int imageWidth = 640;
    public int imageHeight = 480;
    [Range(0.1f, 120f)] public float fieldOfView = 60f;

    [Header("ROS Configuration")]
    public string imageTopic = "/camera/image_raw";
    public float publishRate = 30f; // Hz

    private ROSConnection ros;
    private RenderTexture renderTexture;
    private Texture2D texture2D;
    private float lastPublishTime;

    void Start()
    {
        ros = ROSConnection.GetOrCreateInstance();

        // Setup camera
        if (sensorCamera == null)
            sensorCamera = GetComponent<Camera>();

        sensorCamera.fieldOfView = fieldOfView;

        // Create render texture
        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);
        sensorCamera.targetTexture = renderTexture;

        // Create texture for reading
        texture2D = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);

        lastPublishTime = Time.time;
    }

    void Update()
    {
        if (Time.time - lastPublishTime >= 1f / publishRate)
        {
            PublishCameraImage();
            lastPublishTime = Time.time;
        }
    }

    void PublishCameraImage()
    {
        // Copy render texture to regular texture
        RenderTexture.active = renderTexture;
        texture2D.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);
        texture2D.Apply();

        // Convert texture to ROS image message
        var imageMsg = new ImageMsg();
        imageMsg.header = new std_msgs.Header();
        imageMsg.header.stamp = new builtin_interfaces.Time();
        imageMsg.header.frame_id = transform.name;

        imageMsg.height = (uint)imageHeight;
        imageMsg.width = (uint)imageWidth;
        imageMsg.encoding = "rgb8";
        imageMsg.is_bigendian = 0;
        imageMsg.step = (uint)(imageWidth * 3); // 3 bytes per pixel (RGB)

        // Convert texture to byte array
        byte[] imageData = texture2D.EncodeToPNG();
        imageMsg.data = imageData;

        ros.Publish(imageTopic, imageMsg);
    }

    void OnDestroy()
    {
        if (renderTexture != null)
            RenderTexture.ReleaseTemporary(renderTexture);
        if (texture2D != null)
            Destroy(texture2D);
    }
}
```

## Advanced Simulation Features

### Terrain and Environment

```csharp
// UnityTerrainManager.cs - Terrain and environment setup
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Nav;

public class UnityTerrainManager : MonoBehaviour
{
    [Header("Terrain Configuration")]
    public Terrain terrain;
    public float terrainScale = 100f;
    public int resolution = 257;

    [Header("Environment")]
    public Material[] groundMaterials;
    public GameObject[] obstaclePrefabs;

    [Header("ROS Integration")]
    public string occupancyGridTopic = "/map";

    private float[,] heightmap;

    void Start()
    {
        GenerateTerrain();
        PublishOccupancyGrid();
    }

    void GenerateTerrain()
    {
        if (terrain == null) return;

        // Configure terrain settings
        terrain.terrainData.size = new Vector3(terrainScale, 20f, terrainScale);
        terrain.terrainData.heightmapResolution = resolution;

        // Generate heightmap (simple example - can be more complex)
        heightmap = new float[resolution, resolution];
        for (int i = 0; i < resolution; i++)
        {
            for (int j = 0; j < resolution; j++)
            {
                float x = (float)i / resolution * terrainScale;
                float z = (float)j / resolution * terrainScale;

                // Generate terrain with noise
                float height = Mathf.PerlinNoise(x * 0.05f, z * 0.05f) * 5f;

                // Add some obstacles
                if (Mathf.PerlinNoise(x * 0.1f, z * 0.1f) > 0.7f)
                    height += 2f;

                heightmap[i, j] = height / 20f; // Normalize to 0-1 range
            }
        }

        // Apply heightmap
        terrain.terrainData.SetHeights(0, 0, heightmap);

        // Apply splatmap for textures
        ApplySplatmap();
    }

    void ApplySplatmap()
    {
        if (groundMaterials.Length == 0) return;

        SplatPrototype[] splatPrototypes = new SplatPrototype[groundMaterials.Length];
        for (int i = 0; i < groundMaterials.Length; i++)
        {
            splatPrototypes[i] = new SplatPrototype();
            splatPrototypes[i].texture = groundMaterials[i].mainTexture;
            splatPrototypes[i].tileSize = new Vector2(5f, 5f);
        }

        terrain.terrainData.splatPrototypes = splatPrototypes;

        // Create alphamap
        float[,,] alphamap = new float[resolution, resolution, groundMaterials.Length];
        for (int i = 0; i < resolution; i++)
        {
            for (int j = 0; j < resolution; j++)
            {
                // Simple distribution based on height
                float height = heightmap[i, j];
                if (height < 0.2f)
                    alphamap[i, j, 0] = 1f; // Low ground
                else if (height < 0.6f)
                    alphamap[i, j, 1] = 1f; // Mid ground
                else
                    alphamap[i, j, 2] = 1f; // High ground
            }
        }

        terrain.terrainData.SetAlphamaps(0, 0, alphamap);
    }

    void PublishOccupancyGrid()
    {
        var gridMsg = new OccupancyGridMsg();
        gridMsg.header = new std_msgs.Header();
        gridMsg.header.stamp = new builtin_interfaces.Time();
        gridMsg.header.frame_id = "map";

        // Set metadata
        gridMsg.info = new MapMetaDataMsg();
        gridMsg.info.resolution = terrainScale / resolution;
        gridMsg.info.width = (uint)resolution;
        gridMsg.info.height = (uint)resolution;
        gridMsg.info.origin = new geometry_msgs.Pose();
        gridMsg.info.origin.position.x = -terrainScale / 2f;
        gridMsg.info.origin.position.y = -terrainScale / 2f;

        // Convert heightmap to occupancy values
        gridMsg.data = new int8[resolution * resolution];
        for (int i = 0; i < resolution; i++)
        {
            for (int j = 0; j < resolution; j++)
            {
                // Simple conversion: heights > threshold = obstacle
                float height = heightmap[i, j] * 20f; // Convert back to actual height
                if (height > 3f) // Obstacle threshold
                    gridMsg.data[i * resolution + j] = (sbyte)100; // Occupied
                else
                    gridMsg.data[i * resolution + j] = (sbyte)0; // Free
            }
        }

        ROSConnection.GetOrCreateInstance().Publish(occupancyGridTopic, gridMsg);
    }
}
```

### Animation and Movement Systems

```csharp
// UnityHumanoidMovement.cs - Humanoid movement controller
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Geometry;

public class UnityHumanoidMovement : MonoBehaviour
{
    [Header("Movement Configuration")]
    public float walkSpeed = 2.0f;
    public float runSpeed = 4.0f;
    public float turnSpeed = 90.0f;
    public float stepHeight = 0.3f;

    [Header("Balance Configuration")]
    public Transform centerOfMass;
    public float balanceThreshold = 0.1f;

    [Header("ROS Integration")]
    public string cmdVelTopic = "/cmd_vel";
    public string odomTopic = "/odom";

    private ROSConnection ros;
    private Rigidbody rb;
    private Vector3 targetVelocity;
    private Vector3 targetAngularVelocity;
    private bool isBalanced = true;

    void Start()
    {
        ros = ROSConnection.GetOrCreateInstance();
        rb = GetComponent<Rigidbody>();

        // Subscribe to velocity commands
        ros.Subscribe<TwistMsg>(cmdVelTopic, OnVelocityCommandReceived);

        // Set center of mass
        if (centerOfMass != null && rb != null)
        {
            rb.centerOfMass = transform.InverseTransformPoint(centerOfMass.position);
        }

        // Start publishing odometry
        InvokeRepeating("PublishOdometry", 0f, 0.02f); // 50Hz
    }

    void FixedUpdate()
    {
        ApplyMovement();
        CheckBalance();
    }

    void OnVelocityCommandReceived(TwistMsg cmd)
    {
        // Convert ROS velocity command to Unity movement
        targetVelocity = new Vector3((float)cmd.linear.y, 0, (float)cmd.linear.x) * walkSpeed;
        targetAngularVelocity = Vector3.up * (float)cmd.angular.z * turnSpeed * Mathf.Deg2Rad;
    }

    void ApplyMovement()
    {
        if (rb == null) return;

        // Apply linear movement
        Vector3 movement = transform.TransformDirection(targetVelocity) * Time.fixedDeltaTime;
        rb.MovePosition(rb.position + movement);

        // Apply angular movement
        Quaternion rotation = Quaternion.Euler(targetAngularVelocity * Time.fixedDeltaTime);
        rb.MoveRotation(rb.rotation * rotation);
    }

    void CheckBalance()
    {
        if (centerOfMass == null) return;

        // Calculate center of mass position relative to feet
        Vector3 comProjection = new Vector3(centerOfMass.position.x, transform.position.y, centerOfMass.position.z);
        float distanceToCenter = Vector3.Distance(comProjection, transform.position);

        isBalanced = distanceToCenter < balanceThreshold;

        if (!isBalanced)
        {
            Debug.LogWarning("Humanoid robot is out of balance!");
        }
    }

    void PublishOdometry()
    {
        var odomMsg = new OdometryMsg();
        odomMsg.header = new std_msgs.Header();
        odomMsg.header.stamp = new builtin_interfaces.Time();
        odomMsg.header.frame_id = "odom";
        odomMsg.child_frame_id = "base_link";

        // Set position
        odomMsg.pose.pose = new geometry_msgs.Pose();
        odomMsg.pose.pose.position = new geometry_msgs.Vector3();
        odomMsg.pose.pose.position.x = transform.position.x;
        odomMsg.pose.pose.position.y = transform.position.y;
        odomMsg.pose.pose.position.z = transform.position.z;

        // Set orientation
        odomMsg.pose.pose.orientation = new geometry_msgs.Quaternion();
        odomMsg.pose.pose.orientation.w = transform.rotation.w;
        odomMsg.pose.pose.orientation.x = transform.rotation.x;
        odomMsg.pose.pose.orientation.y = transform.rotation.y;
        odomMsg.pose.pose.orientation.z = transform.rotation.z;

        // Set velocities
        odomMsg.twist.twist = new geometry_msgs.Twist();
        odomMsg.twist.twist.linear = new geometry_msgs.Vector3();
        odomMsg.twist.twist.linear.x = rb.velocity.z;
        odomMsg.twist.twist.linear.y = rb.velocity.x;
        odomMsg.twist.twist.linear.z = rb.velocity.y;

        odomMsg.twist.twist.angular = new geometry_msgs.Vector3();
        odomMsg.twist.twist.angular.z = rb.angularVelocity.y;

        ros.Publish(odomTopic, odomMsg);
    }
}
```

## Performance Optimization

### LOD (Level of Detail) System

```csharp
// UnityLODController.cs - Level of Detail for humanoid models
using UnityEngine;

[RequireComponent(typeof(LODGroup))]
public class UnityLODController : MonoBehaviour
{
    [Header("LOD Configuration")]
    public float[] lodDistances = {10f, 30f, 50f};
    public Renderer[] highDetailRenderers;
    public Renderer[] mediumDetailRenderers;
    public Renderer[] lowDetailRenderers;

    private LODGroup lodGroup;
    private LOD[] lods;

    void Start()
    {
        lodGroup = GetComponent<LODGroup>();
        CreateLODs();
    }

    void CreateLODs()
    {
        lods = new LOD[lodDistances.Length];

        for (int i = 0; i < lodDistances.Length; i++)
        {
            // Create LOD with specific renderers
            Renderer[] renderers;
            switch (i)
            {
                case 0: renderers = highDetailRenderers; break;
                case 1: renderers = mediumDetailRenderers; break;
                default: renderers = lowDetailRenderers; break;
            }

            lods[i] = new LOD(lodDistances[i], renderers);
        }

        lodGroup.SetLODs(lods);
        lodGroup.RecalculateBounds();
    }
}
```

### Occlusion Culling and Rendering Optimization

```csharp
// UnityRenderingOptimizer.cs - Rendering optimization
using UnityEngine;

public class UnityRenderingOptimizer : MonoBehaviour
{
    [Header("Occlusion Culling")]
    public bool useOcclusionCulling = true;
    public LayerMask cullingMask = -1;

    [Header("Dynamic Batching")]
    public bool enableDynamicBatching = true;

    [Header("LOD Bias")]
    [Range(0.1f, 2.0f)] public float lodBias = 1.0f;

    void Start()
    {
        // Configure rendering settings
        QualitySettings.lodBias = lodBias;
        QualitySettings.maxQueuedFrames = 2;

        // Enable/disable features based on settings
        if (enableDynamicBatching)
        {
            // Dynamic batching is enabled by default in Unity
        }
    }

    void Update()
    {
        // Update camera-based optimizations
        Camera[] cameras = Camera.allCameras;
        foreach (Camera cam in cameras)
        {
            if (cam.CompareTag("MainCamera"))
            {
                // Configure main camera for optimal performance
                cam.layerCullDistances = new float[32];
                // Set culling distances for different layers
            }
        }
    }
}
```

## Debugging and Visualization Tools

### Unity Debug Visualization

```csharp
// UnityDebugVisualizer.cs - Debug visualization tools
using UnityEngine;

public class UnityDebugVisualizer : MonoBehaviour
{
    [Header("Debug Visualization")]
    public bool showCOM = true;
    public bool showSupportPolygon = true;
    public bool showIKTargets = true;
    public Color comColor = Color.red;
    public Color supportPolygonColor = Color.green;
    public Color ikTargetColor = Color.blue;

    [Header("Humanoid Configuration")]
    public Transform centerOfMass;
    public Transform[] feet;
    public Transform[] ikTargets;

    void OnDrawGizmos()
    {
        if (showCOM && centerOfMass != null)
        {
            Gizmos.color = comColor;
            Gizmos.DrawSphere(centerOfMass.position, 0.1f);
            Gizmos.DrawLine(transform.position, centerOfMass.position);
        }

        if (showSupportPolygon && feet.Length >= 2)
        {
            Gizmos.color = supportPolygonColor;

            // Draw support polygon between feet
            for (int i = 0; i < feet.Length; i++)
            {
                int next = (i + 1) % feet.Length;
                Gizmos.DrawLine(feet[i].position, feet[next].position);
            }
        }

        if (showIKTargets && ikTargets != null)
        {
            Gizmos.color = ikTargetColor;
            foreach (Transform target in ikTargets)
            {
                if (target != null)
                {
                    Gizmos.DrawWireCube(target.position, Vector3.one * 0.1f);
                }
            }
        }
    }
}
```

## Integration Best Practices

### Unity-ROS Communication Patterns

```csharp
// UnityROSBridge.cs - Best practices for Unity-ROS communication
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using System.Collections.Generic;

public class UnityROSBridge : MonoBehaviour
{
    [Header("Communication Settings")]
    public float messageQueueSize = 100;
    public float networkTimeout = 5.0f;

    private Dictionary<string, Queue<object>> messageQueues = new Dictionary<string, Queue<object>>();
    private float lastHeartbeat;

    void Start()
    {
        // Initialize ROS connection with error handling
        try
        {
            ROSConnection.GetOrCreateInstance().OnConnectionTimeout += OnConnectionTimeout;
            lastHeartbeat = Time.time;
        }
        catch (System.Exception e)
        {
            Debug.LogError($"Failed to initialize ROS connection: {e.Message}");
        }
    }

    void Update()
    {
        // Send periodic heartbeat
        if (Time.time - lastHeartbeat > 1.0f)
        {
            SendHeartbeat();
            lastHeartbeat = Time.time;
        }

        // Process message queues
        ProcessMessageQueues();
    }

    void SendHeartbeat()
    {
        // Send heartbeat to ROS to maintain connection
        var heartbeatMsg = new RosMessageTypes.Std.TimeMsg();
        heartbeatMsg.sec = (int)Time.time;
        heartbeatMsg.nanosec = (uint)((Time.time % 1) * 1e9);

        try
        {
            ROSConnection.GetOrCreateInstance().Publish("/unity_heartbeat", heartbeatMsg);
        }
        catch (System.Exception e)
        {
            Debug.LogWarning($"Heartbeat failed: {e.Message}");
        }
    }

    void ProcessMessageQueues()
    {
        // Process queued messages with rate limiting
        foreach (var queue in messageQueues.Values)
        {
            // Limit processing to avoid overwhelming ROS
            int processCount = Mathf.Min(10, queue.Count);
            for (int i = 0; i < processCount; i++)
            {
                if (queue.Count > 0)
                {
                    var msg = queue.Dequeue();
                    // Process message
                }
            }
        }
    }

    void OnConnectionTimeout()
    {
        Debug.LogError("ROS connection timed out!");
        // Implement reconnection logic here
    }

    public void QueueMessage(string topic, object message)
    {
        if (!messageQueues.ContainsKey(topic))
        {
            messageQueues[topic] = new Queue<object>();
        }

        if (messageQueues[topic].Count < messageQueueSize)
        {
            messageQueues[topic].Enqueue(message);
        }
        else
        {
            Debug.LogWarning($"Message queue for {topic} is full, dropping message");
        }
    }
}
```

## Troubleshooting Common Issues

### Connection and Performance Issues

1. **Network Connection Problems:**
   - Verify ROS master is running: `ros2 daemon status`
   - Check IP address and port configuration
   - Ensure firewall allows connections on the specified port

2. **Performance Optimization:**
   - Reduce physics update rate for complex humanoid models
   - Use occlusion culling for large environments
   - Implement LOD systems for distant objects
   - Use object pooling for frequently instantiated objects

3. **Synchronization Issues:**
   - Ensure Unity and ROS time synchronization
   - Use appropriate message rates to avoid network congestion
   - Implement proper error handling for dropped messages

## Summary

Unity integration provides a powerful platform for humanoid robotics simulation with high-quality visualization and user interaction capabilities. By properly configuring ROS communication, physics, and sensor simulation, developers can create realistic and visually impressive simulation environments. The combination of Unity's rendering capabilities with ROS's robotics framework enables advanced development and testing scenarios for humanoid robots. Proper optimization and debugging practices ensure stable and efficient simulation performance.